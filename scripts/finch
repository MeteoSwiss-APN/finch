#!/usr/bin/env python3

import argparse
import logging
import os
import pathlib
import sys

import matplotx
import yaml

# command line arguments
parser = argparse.ArgumentParser()

parser.add_argument("-d", "--debug", action="store_true", help="Run finch in debug mode")
parser.add_argument("-c", "--config", help="Specify the location of a config file.")
parser.add_argument("-p", "--debug-config", help="Specify the location of a debug config file.")

cmd_args = parser.parse_args(sys.argv[1:])

# debug arguments must be set before importing finch
debug = cmd_args.debug
"""Debug mode"""
os.environ["DEBUG"] = str(debug)

if 1:  # hack for flake8 to ignore E402
    import xarray as xr

    import finch
    import finch.brn

# script

if __name__ == "__main__":

    # configure logging
    logging.basicConfig(format=finch.cfg.get("global", "log_format"), level=logging.WARNING)

    # configure debug setup
    if debug:
        logging.basicConfig(level=logging.DEBUG)
        finch.set_log_level(logging.DEBUG)

    # prepare yaml parsing
    # create config cunstructor to handle config objects
    def config_constructor(
        loader: yaml.Loader, tag_suffix: str, node: yaml.Node
    ) -> list[finch.util.Config] | finch.util.Config:
        node_line = node.start_mark.line
        if isinstance(node, yaml.MappingNode):
            """Handles a single config node"""
            mapping = loader.construct_mapping(node, deep=True)
            if tag_suffix == "Run":
                if "impl" in mapping and mapping["impl"]:
                    impl = mapping["impl"]
                    if isinstance(impl, str):
                        if "." in impl:
                            impl = [impl]
                    if isinstance(impl, str):
                        # this must be a module-only string now
                        module = getattr(globals()["finch"], impl)
                        impl = module.list_implementations()
                    else:
                        _impl = []
                        for i in impl:
                            i = i.split(".")
                            module = getattr(globals()["finch"], i[0])
                            module = getattr(module, "impl")
                            _impl.append(getattr(module, i[1]))
                        impl = _impl
                    mapping["impl"] = impl
                else:
                    raise yaml.YAMLError(f"'impl' attribute must be specified in Run config at line {node_line}")
                # add dummy input object
                mapping["input_obj"] = finch.brn.get_brn_input()
                cfg_lister = finch.OperatorRunConfig.list_configs
            elif tag_suffix == "Cluster":
                cfg_lister = finch.scheduler.ClusterConfig.list_configs
            elif tag_suffix == "Version":
                if fmt := mapping.get("format"):
                    if isinstance(fmt, str):
                        fmt = [fmt]
                    mapping["format"] = [finch.data.Format(f) for f in fmt]
                cfg_lister = finch.data.Input.Version.list_configs
            else:
                raise yaml.YAMLError(f"Unsupported config '{tag_suffix}' at line {node_line}")
            out = cfg_lister(**mapping)
            if len(out) == 1:
                return out[0]
            else:
                return out
        elif isinstance(node, yaml.SequenceNode):
            out = loader.construct_sequence(node, deep=True)
            out = finch.util.flat_list(out)
            if len(out) == 1:
                return out[0]
            else:
                return out
        else:
            raise yaml.YAMLError(f"!config: tag is only supported for mappings and lists. Error at line {node_line}")

    yaml.add_multi_constructor("!config:", config_constructor, Loader=yaml.SafeLoader)

    # load configurations
    default_config_path = pathlib.Path(finch.env.data_dir, "config", "run.yaml")
    with open(default_config_path) as f:
        rc: dict = yaml.safe_load(f)
    custom_config_path = pathlib.Path(cmd_args.config or finch.cfg.get("run", "config_path"))
    if custom_config_path.exists():
        with open(custom_config_path) as f:
            custom_config: dict = yaml.safe_load(f)
            rc = finch.util.recursive_update(rc, custom_config)
    if debug:
        debug_config_path = pathlib.Path(finch.env.data_dir, "config", "debug.yaml")
        with open(debug_config_path) as f:
            dbg_config: dict = yaml.safe_load(f)
            rc = finch.util.recursive_update(rc, dbg_config)
        custom_debug_config_path = pathlib.Path(cmd_args.debug_config or finch.cfg.get("run", "debug_config_path"))
        if custom_debug_config_path.exists():
            with open(custom_debug_config_path) as f:
                dbg_config: dict = yaml.safe_load(f)
                rc = finch.util.recursive_update(rc, dbg_config)

    rc = finch.util.RecursiveNamespace(**rc)

    # brn experiments

    brn_input = finch.brn.get_brn_input()

    if rc.brn.run:

        measure_cfg = dict(pbar=rc.general.pbar)

        rcc = rc.brn.input_management
        if rcc.run:
            logging.info("Adding new input version")
            if rcc.add_version:
                finch.scheduler.start_scheduler(debug, rcc.cluster)
                finch.scheduler.scale_and_wait(rcc.workers)
                brn_input.add_version(rcc.add_version)

        rcc = rc.brn.runtime_measurement
        if rcc.run:
            logging.info("Measuring runtimes of brn implementations")
            for run_config in rcc.run_configs:
                run_config.input_obj = brn_input
            times = finch.measure_runtimes(rcc.run_configs, **measure_cfg)
            results = finch.eval.create_result_dataset(times, rcc.run_configs, "brn_" + rcc.exp_name)
            results.to_netcdf(rc.results_file)

        rcc = rc.brn.evaluation
        if rcc.run:
            logging.info("Evaluating experiment results")
            if not rcc.plot_dark_mode:
                finch.eval.plot_style = matplotx.styles.dufte
            if rcc.exp_name is None:
                results = xr.open_dataset(rc.results_file)
                results.to_netcdf(
                    finch.util.get_path(finch.cfg.get("evaluation", "results_dir"), results.attrs["name"], "results.nc")
                )
            else:
                results = xr.open_dataset(
                    finch.util.get_path(finch.cfg.get("evaluation", "results_dir"), rcc.exp_name, "results.nc")
                )
            results = finch.eval.create_cores_dimension(results)
            if rcc.rename_labels:
                brn_eval_rename_labels = {rcc.main_dim: rcc.rename_labels}
                results = finch.eval.rename_labels(results, brn_eval_rename_labels)
            if rcc.ignore_labels:
                results = finch.eval.remove_labels(results, rcc.ignore_labels, rcc.main_dim)
            if rcc.add_runtimes:
                for k, v in rcc.add_runtimes.items():
                    results = finch.eval.add_runtimes(results, k, v)
            finch.eval.create_plots(
                results,
                main_dim=rcc.main_dim,
                scaling_dims=rcc.speedup_dims,
                relative_rt_dims=rcc.reference_labels,
                runtime_selection=rcc.runtimes_plot,
                estimate_serial=rcc.estimate_serial,
                plot_scaling_fits=rcc.plot_fit,
            )
            if len(results.data_vars) > 1:
                finch.eval.plot_runtime_parts(results, first_dims=rcc.rt_parts_order)
            finch.eval.store_config(results)
